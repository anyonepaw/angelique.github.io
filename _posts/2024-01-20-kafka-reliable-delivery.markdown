---
layout: post
title:  ":book: Kafka patterns for microservices - transactional outbox (inbox)"
date: 2024-01-20 00:42:07 +0300
categories: develop
tags: pattern
---

#### **Источники:**

https://microservices.io/patterns/data/event-driven-architecture.html

https://www.youtube.com/watch?v=EYtg3WiGHSU

https://softwaremill.com/microservices-101/

Надежно отправляем события в Apache Kafka. От CDC до паттерна Transactional Outbox



# Обеспечиваем консистентность между сервисами с помощью Kafka

Распределенная микросервисная система

Базы данных

Мы храним данные

Другие системы ходят к нам за данными

![img_1.png](../assets/images/img_1.png)

# Transactional outbox (и inbox):

- Микросервисный паттерн
- Event-driven architecture (Событийно-ориентированная архитектура)
- в книге - шаблон "публикация событий"
- справедлив для любого брокера, поддерживающего at-least

![img_2.png](../assets/images/img_2.png)

# outbox
В микросервисной архитектуре не редка ситуация коммуникации микросервисов посредством публикации событий. Происходит изменение состояния какой-либо сущности в одном из микросервисов и для информирования других сервисов публикуется событие об изменение данной сущности. Проблема кроется в том, что эти два действия - сохранение состояния и публикация события - обычно не происходят атомарно. А это означает, что на любом из указанных этапов что-то может пойти не так, и одно из действий не будет выполнено, что оставит систему в несогласованном состоянии. В качестве решения предлагается в начале в рамках одной транзакции атомарно сохранять и изменения и само событие, а вторым шагом выполнять публикацию ранее сохраненного события.

Основная идея: вместо того, чтобы отправить сообщение напрямую во время выполнения бизнес-операции,
сообщение записывается в специальную таблицу баз данных (outbox).

Эта запись в "outbox" совершается в той же транзакции, что и основные изменения данных,
таким образом обеспечивается "атомарность".


---

# inbox

(@MicroservicesThoughts https://t.me/MicroservicesThoughts/90):

У транзакционного аутбокса можно выделить два вида:

Например, консьюмеру необходимо **ровно один раз** обработать сообщение

```
processMessage() {
  databaseTx { // Может случиться ситуация, что databaseTx закоммитилась, но 
    …
  }
  message.commit() //message.commit() не отработал
}
//из-за этого мы снова обработаем то же сообщение
```

1) на основе ключа сообщения

```
processMessage() { // По-прежнему сначала обрабатываем сообщение
    databaseTx {
        if (!tryInsert(msgKey)) { //Но добавляем дедупликацию
            message.commit()
            return
        }
        …
    }
    message.commit() //потом коммитим
}
```

В таком случае даже если databaseTx закоммитилась, но message.commit() не отработал, то при повторном чтении мы увидим сохраненный ключ сообщения, и сразу его закоммитим

tryInsert ~ insert on conflict do nothing, который либо ничего не вставляет, либо вставляет и держит блокировку на ключ до окончания транзакции

В первом варианте подразумевается, что процессим сообщение прямо в рамках датабазной транзакции, поэтому если она упадёт, то и ключ в базу не вставится, и сообщение не подтвердится

Долгие транзакции действительно проблема, если нужно делать какие-то тяжелые вещи, делать кучу походов вовне. Но можно постараться вынести их из транзакции по возможности. Зачастую обработка сообщения — это локальная транзакция + коммит сообщения в transactional outbox, в таком случае всё будет ок


- В этом варианте же есть еще момент, что мы держим соединение к базе на все время обработки события.
Еще как вариант без транзакций, если 100%-ая гарантия не требуется, то можно перед обработкой положить msgKey в redis set, если получилось - обрабатываем, иначе скип

2) используем таблицу

Сохраняем сообщение в таблицу, и фоновые воркеры достают сообщения из таблицы и обрабатывают
```
processMessage() {
    databaseTx {
        tryInsert(message)
    }
    message.commit()
}
```
_pros:_
Несмотря на то, что такой подход решает ту же проблему, еще и при этом добавляет latency, у него есть весомый плюс — консюмер теперь может балансировать нагрузку на себя

Причем это работает в обе стороны:

1) Например, если сообщения в нас отправляют по http со слишком высоким рейтом, то мы просто сохраняем их в таблицу и процессим с доступной нам скоростью


2) И наоборот: если сообщения мы сами читаем из топика, но у топика слишком мало партиций,
и существующие консюмеры не успевают обрабатывать приходящие сообщения, то можно также их просто сохранить в таблицу, и далее нужным количеством воркеров разгребать эту таблицу

_cons:_ при использовании таблицы, если использвуется >1 воркера порядок сообщений при вычитке из таблицы может потеряться.
Тогда достаточно поддерживать не глобальную очередность, 
а очередность в рамках какого-то ключа. Например, чтобы события по одному агрегату шли гарантированно очередно.
И тогда можно уже делать, чтобы несколько воркеров вычитывали.

### CDC (Change Data Capture)
Более сложный подход к получению данных из таблицы исходящих сообщений называется отслеживанием журналов базы данных. В реляционных базах данных каждая операция записывается в WAL (журнал упреждающей записи). Позже его можно запросить о новых записях, касающихся строк, вставленных в папку исходящих сообщений. Этот вид обработки называется CDC (фиксация изменения данных). Чтобы использовать этот метод, ваша база данных должна предлагать возможности CDC или вам нужно будет использовать какую-то структуру (например, Debezium).